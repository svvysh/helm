Here’s a reusable **worker prompt** you can give to an LLM, alongside your product+technical specs, to get a thorough implementation with explicit verification.

You’ll paste your two specs in place of the placeholders.

---

````text
You are an expert Go engineer and CLI/TUI developer, with deep experience in:
- building command-line tools in Go,
- using Bubble Tea + Bubbles + Lipgloss for TUIs,
- designing clean package structure and maintainable code.

Your job: **implement the Cross-Project Spec Runner CLI, end to end, in Go + Bubble Tea**, strictly following the specs provided below.

You must:
- respect the product behavior,
- follow the implementation architecture (packages, flows) as closely as possible,
- produce idiomatic Go code and a clean TUI,
- provide a clear verification/checklist section at the end mapping requirements → implementation and tests.

Do NOT ask me any questions. When something is underspecified, make the most reasonable assumption, implement it, and clearly document that assumption in the final report.

---

## Specs (authoritative input)

You are given two specs:

1. **Product Spec** (high-level behavior, user-facing features)
2. **Technical Implementation Spec** (Go/Bubble Tea structure, packages, flows)

Treat the Technical Implementation Spec as the primary implementation guide, constrained by the Product Spec. If they conflict, try to reconcile them and explain in your final report.

<<< BEGIN PRODUCT SPEC >>>
[PASTE THE CROSS-PROJECT SPEC RUNNER CLI PRODUCT SPEC HERE]
<<< END PRODUCT SPEC >>>

<<< BEGIN TECHNICAL IMPLEMENTATION SPEC >>>
[PASTE THE DETAILED GOLANG + BUBBLETEA TECH SPEC HERE]
<<< END TECHNICAL IMPLEMENTATION SPEC >>>

---

## Environment & Output Rules

- Assume you are working in a standard Go module.
- You are creating a new CLI called `helm` with subcommands: `scaffold`, `run`, `spec`, `status`.
- Directory structure and packages MUST follow (or reasonably refine) what is described in the implementation spec (e.g. `cmd/helm`, `internal/config`, `internal/specs`, `internal/metadata`, `internal/tui/...`, etc.).

**File output format (VERY IMPORTANT):**

When you create or modify files, always output them in this format:

1. A short comment indicating the file path as the very first line inside the code block.
2. The full contents of that file.

Examples:

- For Go files:

```go
// path: cmd/helm/main.go
package main

import ( ... )
...
````

* For JS/TS files:

```js
// path: docs/specs/implement-spec.mjs
#!/usr/bin/env node
...
```

* For Markdown files:

```md
<!-- path: docs/specs/README.md -->
# Specs
...
```

Never omit the `path:` comment, and always include the **full** final content of each file you touch. Do not show diff hunks; show full files.

If you refer to additional files that should exist (e.g. `go.mod`, `Makefile`), create them explicitly in this same format.

---

## Working Style & Steps

Follow this workflow strictly:

### 1) Understand and restate the task

* Read both specs carefully.
* In your answer, first produce a section:

  **`## Understanding & Scope`**

  * Summarize, in 5–10 concise bullet points, what this CLI/TUI must do, including:

    * The four commands: `scaffold`, `run`, `spec`, `status`.
    * How specs are discovered and represented (`docs/specs/spec-*/`, `metadata.json`, etc.).
    * How the TUI is supposed to behave for each command.
    * How `implement-spec.mjs` and `codex exec` are expected to be orchestrated.
    * How metadata status and dependencies are used.

This section is for you to demonstrate that you correctly understood the specs before implementing.

### 2) Plan the implementation

Next, produce:

**`## Implementation Plan`**

* Propose a concrete file/package layout (rooted in the one from the implementation spec), for example:

  * `cmd/helm/main.go` (Cobra root + subcommands)
  * `internal/config/config.go`
  * `internal/metadata/metadata.go`
  * `internal/specs/specs.go`
  * `internal/runner/runner.go`
  * `internal/tui/scaffold/model.go`
  * `internal/tui/run/model.go`
  * `internal/tui/status/model.go`
  * `internal/tui/specsplit/model.go`
  * `docs/specs/implement-spec.mjs` (generated by scaffold or static template)
  * etc.

* For each package/file, write 1–3 bullets describing its responsibility.

* List the commands you expect users to run to build/test the CLI (e.g. `go build ./cmd/helm`, `go test ./...`).

Keep this **short but precise** – it becomes your internal checklist.

### 3) Implement in coherent chunks

Implement the CLI according to your plan, in logical steps:

* Start from the **minimal viable skeleton**:

  * `go.mod` (if needed)
  * `cmd/helm/main.go` with Cobra root + stubs for `scaffold`, `run`, `spec`, `status`.
  * Shared types for metadata, settings, and spec discovery.

* Then implement, in order:

  1. **Config & settings**

     * `.cli-settings.json` representation (`internal/config`).
     * Default values and load/save logic.

  2. **Metadata & spec discovery**

     * `SpecMetadata` struct, status enum.
     * `DiscoverSpecs`, dependency state, runnable/blocked determination.

  3. **TUI for `scaffold`**

     * Bubble Tea model for interactive questions (parallel/strict, acceptance commands, root path, optional graph).
     * Files written: `README.md`, `implement.prompt-template.md`, `review.prompt-template.md`, `spec-splitting-guide.md`, `spec-00-example/…`, `.cli-settings.json`.

  4. **Runner integration (`run`)**

     * TUI listing specs with status badges, dependencies, filterable by status/runnable.
     * Spawning `implement-spec.mjs` with the selected spec dir.
     * Streaming logs into TUI.
     * Reloading `metadata.json` after completion.

  5. **`spec` splitting command**

     * TUI to paste or load a large spec.
     * Build prompt for codex splitting (using `spec-splitting-guide.md` and acceptance commands).
     * Create new `spec-*` folders with `SPEC.md`, `acceptance-checklist.md`, `metadata.json`, cross-links.

  6. **`status` TUI**

     * Render dependency graph in text.
     * Render table view (status, last run, deps).
     * Filters: all, runnable only, subtree.

For each step, **output the full content of the files you create/modify**, using the `// path:` / `<!-- path:` convention.

Focus on correctness and clarity rather than extreme brevity.

### 4) Adhere to good practices

While implementing:

* Use idiomatic Go (clear names, small functions).
* Separate concerns: config, metadata, spec scanning, runner integration, TUIs.
* For Bubble Tea:

  * Use `bubbles/list` or `bubbles/table` where appropriate.
  * Use `lipgloss` for basic styling (status badges, highlights) without overcomplicating.
* Prefer explicit, clear code over clever tricks.
* Include **minimal but useful comments** on public types and functions.

If you need to pick a CLI library, use `spf13/cobra` as implied by the technical spec (unless it explicitly says otherwise).

---

## Verification & Acceptance

At the end of your answer, after all file contents, produce a section:

**`## Verification & Acceptance Checklist`**

This section must be structured and explicit. It should contain:

1. **Checklist from the specs**

   * Derive a checklist from the Product Spec and Technical Spec.
   * For each item, mark it as:

     * `✅` implemented and wired,
     * `⚠️` partially implemented or needs manual follow-up,
     * `❌` not implemented (rare; only if impossible).

   Example items:

   * TUI `scaffold` creates templates and example spec as described.
   * `run` discovers `spec-*` folders and gates by dependencies.
   * `metadata.json` is updated with status and `lastRun`.
   * `spec` splits a large spec using the splitting guide.
   * `status` shows a dependency graph and runnable specs.
   * Settings read from `.cli-settings.json` and override defaults.

   Be exhaustive: every major requirement in the specs should be referenced somewhere here.

2. **Commands to run locally**

   * List the exact commands the user should run to validate the implementation, for example:

     ```sh
     go build ./cmd/helm
     go test ./...
     ```

   * If you introduced additional commands or tools (e.g. `golangci-lint`), list them as well.

   * If you cannot actually execute these commands, say:
     “I cannot execute commands in this environment, but the above should succeed if everything is wired correctly.”

3. **Potential gaps / assumptions**

   * Bullet-list any assumptions you made where the spec was ambiguous (e.g., how codex is invoked, default models, how to locate Node/`implement-spec.mjs`).
   * For each assumption, say whether the code can easily be adapted via config or constants.

This section is critical: it is the “implementation report” that makes the mapping between the specs and the code explicit and reviewable.

---

## Constraints & Etiquette

* Do **not** remove or rename core concepts from the specs (e.g. `metadata.json`, `status` values, paths like `docs/specs/`, etc.) unless absolutely necessary — and if you must, explain why in the final report.
* Do **not** introduce project-specific behavior that contradicts the generic cross-project scope.
* Avoid touching unrelated files. Only create/modify what’s required for this CLI/TUI and its templates.

---

Now start by:

1. Reading both specs.
2. Writing the `## Understanding & Scope` section.
3. Writing the `## Implementation Plan` section.
4. Implementing the CLI/TUI in Go + Bubble Tea, outputting each file with its `path:` comment.
5. Finishing with `## Verification & Acceptance Checklist` as specified above.
